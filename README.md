# Image-captioning-
This project is a full-stack Image Captioning system that automatically generates human-like captions for images using a CNN + RNN/LSTM architecture. The model is trained and evaluated on the Flickr8k dataset, which contains 8,000 images paired with five descriptive captions each.

Features

Interactive website – Upload an image and get an AI-generated caption in real time

Deep learning backend – Uses a pre-trained CNN (e.g., InceptionV3/ResNet) for feature extraction and an LSTM-based RNN for sequence generation

Flickr8k dataset integration – Cleaned and preprocessed dataset with image-text mapping

Training pipeline – Data preprocessing, feature extraction, and caption generation implemented from scratch

Frontend – User-friendly interface with HTML, CSS, and JavaScript

Backend – Python-based model serving (Flask/Django)

Tech Stack

Frontend: HTML, CSS, JavaScript

Backend: Python (Flask/Django)

Deep Learning: TensorFlow/Keras, CNN, LSTM

Dataset: Flickr8k

Use Cases

Assist visually impaired individuals by describing images

Enhance content management and accessibility

Demonstrate deep learning applications in NLP + Computer Vision
